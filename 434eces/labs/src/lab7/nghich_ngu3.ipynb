{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import IPython.display as ipd\n",
    "import scipy.signal as signal\n",
    "from scipy.fftpack import fft, ifft, dct, idct\n",
    "from scipy.signal import butter, lfilter\n",
    "import matplotlib.pyplot as plt\n",
    "import CosineTransformTools as ctt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw_quant(x, mu):\n",
    "    return np.sign(x)*np.log(1 + mu*np.abs(x))/np.log(1 + mu)\n",
    "\n",
    "def inv_powerlaw_quant(y, mu):\n",
    "    return np.sign(y)*((mu + 1)**np.abs(y) - 1)/mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x, S):\n",
    "    X = x.reshape((-1,1))\n",
    "    S = S.reshape((1,-1))\n",
    "    dists = abs(X-S)\n",
    "    \n",
    "    nearestIndex = dists.argmin(axis=1)\n",
    "    quantized = S.flat[nearestIndex]\n",
    "    \n",
    "    return quantized.reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=10):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=10):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_noise(original, decoded):\n",
    "    original = original.astype('float_')\n",
    "    decoded = decoded.astype('float_')\n",
    "    diff = len(original) - len(decoded)\n",
    "    \n",
    "    if diff < 0:\n",
    "        decoded = decoded[:diff]\n",
    "    if diff > 0:\n",
    "        decoded = np.append(decoded, np.zeros((diff,1)))\n",
    "        \n",
    "    signal = np.power(original, 2)\n",
    "    noise = np.power(original-decoded, 2)\n",
    "    \n",
    "    signal = np.where(signal == 0, np.finfo(np.float32).eps, signal)\n",
    "    noise = np.where(noise == 0, np.finfo(np.float32).eps, noise)\n",
    "    \n",
    "    return np.mean(np.log10(signal/noise)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ath(f):\n",
    "    return 3.64*np.float_power(f/1000, -0.8) - \\\n",
    "        6.5*np.exp(-0.6*np.power(f/1000 - 3.3, 2)) + \\\n",
    "        np.float_power(10, -3)*np.power(f/1000, 4)\n",
    "\n",
    "def bark(f):\n",
    "    return 13*np.arctan(0.00076*f) + 3.5*np.arctan((f/7500)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cd_quality_audio(filename):\n",
    "    audio, sr = librosa.load(filename, sr=44100, dtype='float_')\n",
    "    max_int_value = 2**15 - 1\n",
    "    audio *= max_int_value\n",
    "    audio = audio.astype('int16')\n",
    "    return audio, sr\n",
    "    \n",
    "x, sr = load_cd_quality_audio(\"onmyway.wav\")\n",
    "fs = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipd.Audio(x, rate=44100)\n",
    "# x = x[0:1000000]\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_frames(signal, window_length, overlap):\n",
    "    assert(overlap < window_length/2)\n",
    "    # Find out how many frames are needed\n",
    "    nframes = np.ceil((len(signal) + overlap)/(window_length - overlap))\n",
    "    npadded = (nframes*window_length - overlap*(nframes-1)) - len(signal)\n",
    "    print(nframes, npadded)\n",
    "    padded = np.pad(signal, (0, int(npadded)), 'constant', constant_values=0.0)\n",
    "    frames = np.array([padded[i : i + window_length] for i in range(0, len(padded) - window_length, window_length-overlap)])\n",
    "    return frames\n",
    "\n",
    "npoints = 1152\n",
    "overlap = 1152//4\n",
    "nbands = 32\n",
    "\n",
    "# Divide original signal into frames, each frame consists of npoints\n",
    "# x_frames = divide_into_frames(x, npoints, overlap)\n",
    "# x_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "window_length = 64\n",
    "window_function = np.sin(np.pi / 2 * \\\n",
    "                       np.power(np.sin(np.pi / window_length * \\\n",
    "                       np.arange(0.5, window_length + 0.5)), 2))\n",
    "num_blocks = 0\n",
    "plt.plot(window_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class TonalClassifier(object):\n",
    "#     def __init__(self):\n",
    "#         small  = np.array([-2, +2])\n",
    "#         medium = np.array([-3, -2, +2, +3]) \n",
    "#         large  = np.array([-6, -5, -4, -3, -2, +2, +3, +4, +5, +6])\n",
    "#         xlarge  = np.linspace(-12, 12, 25, dtype='int')\n",
    "#         self.neighbourhood = 512 * [None]\n",
    "#         for _k in range(2, 63):\n",
    "#             self.neighbourhood[_k] = small\n",
    "#         for _k in range(63, 127):\n",
    "#             self.neighbourhood[_k] = medium\n",
    "#         for _k in range(127, 255):\n",
    "#             self.neighbourhood[_k] = large\n",
    "#         for _k in range(255, 501):\n",
    "#             self.neighbourhood[_k] = xlarge\n",
    "#     def __call__(self, k, P):\n",
    "#         k_t = []\n",
    "#         P_t = []\n",
    "#         for _k in np.arange(3, 501):\n",
    "#             if (P[_k-1] <= P[_k] and P[_k+1] <= P[_k]):\n",
    "#                 js = self.neighbourhood[_k]\n",
    "#                 if np.all(P[_k] - P[_k+js] >= 7):\n",
    "#                     k_t.append(_k)\n",
    "#                     P_t.append(P[_k-1] + P[_k] + P[_k+1])\n",
    "#                     P[_k-1] = P[_k] = P[_k+1] = 0.0\n",
    "#         return (np.array(k_t), np.array(P_t))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psyacoustic_analysis(sig):\n",
    "    x_fr_stft = librosa.stft(sig.astype('float'), hop_length=window_length//2, win_length=window_length, window=window_function)\n",
    "    x_fr_stft2 = x_fr_stft**2\n",
    "    P_k = 2.0 * x_fr_stft2[:(window_length // 2 + 1)] / window_length ** 2\n",
    "    P_k[0] = 0.5 * P_k[0]\n",
    "    if (window_length % 2 == 0):\n",
    "        P_k[-1] = 0.5 * P_k[-1]\n",
    "    P_k = 10.0 ** (96.0 / 10.0) * P_k\n",
    "    P_k = 10.0 * np.log10(P_k)\n",
    "\n",
    "    dt = 1.0 / sr\n",
    "    k = np.arange(window_length // 2 + 1)\n",
    "    f_k = k * sr / window_length\n",
    "    b_k = bark(f_k)\n",
    "    ath_k = 10 ** (ath(f_k)/10)\n",
    "\n",
    "    ath_k.shape = (len(ath_k),1)\n",
    "    coeffs_bool = (P_k - np.repeat(ath_k, P_k.shape[1], axis=1) <= 0)\n",
    "\n",
    "    P_tonal = np.zeros(P_k.shape)\n",
    "    k_tonal = []\n",
    "    js = np.array([-2, +2])\n",
    "    P_nontonal = np.copy(P_k)\n",
    "    for col in range(0, P_k.shape[1]):\n",
    "        for row in range(3, P_k.shape[0]-3):\n",
    "            if P_k[row,col] >= P_k[row-1,col] and P_k[row,col] >= P_k[row+1,col]:\n",
    "                if np.all(P_k[row,col] - P_k[row+js,col] >= 7):\n",
    "                    P_tonal[row,col] = P_k[row-1,col] + P_k[row,col] + P_k[row+1,col]\n",
    "                    k_tonal.append((row, col))\n",
    "                    P_nontonal[row-1,col] = P_nontonal[row,col] = P_nontonal[row+1,col] = 0.0\n",
    "\n",
    "    decimated_tonal_k = np.zeros(P_k.shape)\n",
    "    for i in range(len(k_tonal)-1):\n",
    "        row, col = k_tonal[i]\n",
    "        next_row, next_col = k_tonal[i+1]\n",
    "        currP = P_tonal[row, col]\n",
    "        nextP = P_tonal[next_row, next_col]\n",
    "\n",
    "        if abs(b_k[row] - b_k[next_row]) < 1:\n",
    "            if currP >= nextP:\n",
    "                coeffs_bool[next_row, next_col] = False\n",
    "            else:\n",
    "                coeffs_bool[row, col] = False\n",
    "    \n",
    "    cb_k = np.array([int(b) for b in np.floor(b_k)])\n",
    "    crit_bands = {}\n",
    "    for col in range(0, P_k.shape[0]):\n",
    "        crit_bands.clear\n",
    "        for row in range(0, P_k.shape[0]):\n",
    "            if cb_k[row] not in crit_bands:\n",
    "                crit_bands[cb_k[row]] = [(P_nontonal[row, col], row)]\n",
    "            else:\n",
    "                crit_bands[cb_k[row]].append((P_nontonal[row, col], row))\n",
    "        \n",
    "        for band in crit_bands.keys():\n",
    "            P_sum = sum(i for i, _ in crit_bands[band])\n",
    "            avg_row = int(round(sum(i for _, i in crit_bands[band])/len(crit_bands[band])))\n",
    "            coeffs_bool[avg_row, col] = False\n",
    "            \n",
    "\n",
    "    return coeffs_bool[1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 100\n",
    "# tmp_psaa = psyacoustic_analysis(x_frames[i,:])\n",
    "# tmp_mdct = ctt.mdct(x_frames[i,:], window_function)\n",
    "# tmp_mdct[tmp_psaa] = 0\n",
    "# tmp_imdct = ctt.imdct(tmp_mdct, window_function)\n",
    "# signal_to_noise(x_frames[i], tmp_imdct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# psyacoustic_analysis(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_to_noise(x, ctt.imdct(ctt.mdct(x, window_function), window_function))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_banks(x, nbands, num_blocks):\n",
    "    x_bands = np.zeros((nbands, num_blocks))\n",
    "    \n",
    "#     for i in range(0, x_frames.shape[0]):\n",
    "    coeff_bool = psyacoustic_analysis(x)\n",
    "\n",
    "    x_bands = ctt.mdct(x, window_function)\n",
    "    coeff_bool = np.pad(coeff_bool, [(0,0), (0, x_bands.shape[1] - coeff_bool.shape[1])], mode='constant', constant_values=1)\n",
    "    x_bands[coeff_bool] = 0\n",
    "        \n",
    "    return x_bands\n",
    "\n",
    "t1 = time.time()\n",
    "x_bands = filter_banks(x, nbands, 31251)\n",
    "num_blocks = x_bands.shape[1]\n",
    "print(time.time() - t1)\n",
    "x_bands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# librosa.display.specshow(x_bands,x_axis='time',y_axis='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = np.array([])\n",
    "# for i in range(x_bands.shape[0]):\n",
    "tmp_imdct = ctt.imdct(x_bands, window_function)\n",
    "\n",
    "tmp = np.append(tmp, tmp_imdct)\n",
    "print(signal_to_noise(x, tmp_imdct))\n",
    "ipd.Audio(tmp.flatten(), rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedFrame(object):\n",
    "    def __init__(self, data=np.array([], dtype='float16')):\n",
    "        self.data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale_table = np.array([14, 14, 14, 15, 15, 15, 16, 16, 16, 18, 18, \\\n",
    "#                    18, 18, 18, 18, 18, 25, 25, 25, 32, 32, 32, 32, 32, 32, 32, \\\n",
    "#                    32, 32, 32, 32, 32, 32], dtype='uint8')\n",
    "\n",
    "# scale_table = np.array([18, 18, 18, 18, 18, 19, 19, 20, 20, 20, 23, \\\n",
    "#                    23, 23, 18, 18, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, \\\n",
    "#                    32, 32, 32, 32, 32, 32], dtype='uint8')\n",
    "\n",
    "scale_table = np.array([19, 19, 19, 19, 19, 21, 21, 21, 32, 20, 23, \\\n",
    "                   23, 23, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, 32, \\\n",
    "                   32, 32, 32, 32, 32, 32], dtype='uint8')\n",
    "\n",
    "def quantization(x_bands):\n",
    "    max_bits = np.max(scale_table)\n",
    "    quantized_signal = []\n",
    "#     frame_separator = 2**(max_bits+1)\n",
    "\n",
    "    quantfr = QuantizedFrame()\n",
    "    for j in range(0, x_bands.shape[0]):\n",
    "        bit_alloc = scale_table[j]\n",
    "        quantized_mdct = powerlaw_quant(x_bands[j], 255)\n",
    "        quantized_mdct = quantized_mdct/(2**bit_alloc)\n",
    "#             print(signal_to_noise(x_subbands[j,i,:], inv_powerlaw_quant(quantized_mdct*band_smr,255)))\n",
    "        quantized_mdct = quantized_mdct.astype('float16')\n",
    "        quantfr.data = np.append(quantfr.data, quantized_mdct)\n",
    "\n",
    "    quantized_signal.append(quantfr)\n",
    "    \n",
    "    return quantized_signal\n",
    "\n",
    "t1 = time.time()\n",
    "quantized_signal = quantization(x_bands)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodedSignal(object):\n",
    "    def __init__(self):\n",
    "        self.data = None\n",
    "        self.scale_table = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "\n",
    "def encoding(quantized_signal):\n",
    "    encoded_signal = EncodedSignal()\n",
    "    encoded_signal.data = quantized_signal\n",
    "    encoded_signal.scale_table = scale_table\n",
    "    i_str = pickle.dumps(encoded_signal)\n",
    "    compressed_signal = bz2.compress(i_str)\n",
    "    \n",
    "    return compressed_signal\n",
    "\n",
    "compressed_signal = encoding(quantized_signal)\n",
    "\n",
    "def compressionRatio(original, decoded):\n",
    "    o_str = pickle.dumps(original)\n",
    "    e_str = pickle.dumps(decoded)\n",
    "    return sys.getsizeof(o_str)/sys.getsizeof(e_str)\n",
    "\n",
    "compressionRatio(x,compressed_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def decode(encoded_signal):\n",
    "    decompressed_signal = pickle.loads(bz2.decompress(compressed_signal))\n",
    "#     empty_frame = [0]*npoints\n",
    "#     mdct_per_frame = num_blocks\n",
    "    mdct_per_frame = num_blocks\n",
    "#     decoded_signal = np.zeros((len(decompressed_signal.data), npoints))\n",
    "    decoded_signal = np.array([])\n",
    "\n",
    "    max_bits = np.max(decompressed_signal.scale_table)\n",
    "\n",
    "    for i, frame in enumerate(decompressed_signal.data):\n",
    "        decoded_mdct = np.zeros((nbands, mdct_per_frame))\n",
    "    #         frame_data = np.array(huffman_decoder.decode(frame.data))\n",
    "        for j in range(0, len(decompressed_signal.scale_table)):\n",
    "            scale_factor = decompressed_signal.scale_table[j]\n",
    "            start = j*mdct_per_frame\n",
    "            end = (j+1)*mdct_per_frame\n",
    "            encoded_mdct = frame.data[start:end]*(2**scale_factor)\n",
    "#             encoded_mdct = frame.data[start:end]\n",
    "            decoded_mdct[j] = inv_powerlaw_quant(encoded_mdct, 255)\n",
    "        decoded_frame = ctt.imdct(decoded_mdct, window_function)\n",
    "        decoded_signal = np.append(decoded_signal, decoded_frame)\n",
    "#         diff = 1152 - len(decoded_frame)\n",
    "#         if diff < 0:\n",
    "#             decoded_signal[i,:] = decoded_frame[:diff]\n",
    "#         if diff > 0:\n",
    "#             decoded_signal[i,:] = np.append(decoded_frame, np.zeros((diff,1)))\n",
    "\n",
    "    return decoded_signal.flatten().astype('int16')\n",
    "\n",
    "t1 = time.time()\n",
    "decoded_signal = decode(compressed_signal)\n",
    "print(time.time() - t1)\n",
    "print(signal_to_noise(x, decoded_signal.flatten()))\n",
    "ipd.Audio(decoded_signal.flatten(), rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_signal[100:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
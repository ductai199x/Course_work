{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import sys\n",
    "import pickle\n",
    "import time\n",
    "import IPython.display as ipd\n",
    "import scipy.signal as signal\n",
    "from scipy.fftpack import fft, ifft, dct, idct\n",
    "from scipy.signal import butter, lfilter\n",
    "import matplotlib.pyplot as plt\n",
    "import CosineTransformTools as ctt \n",
    "from dahuffman import HuffmanCodec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def powerlaw_quant(x, mu):\n",
    "    return np.sign(x)*np.log(1 + mu*np.abs(x))/np.log(1 + mu)\n",
    "#     return np.sign(x)*np.amax(x)*np.log(1 + mu*np.abs(x)/np.amax(x))/np.log(1 + mu)\n",
    "\n",
    "def inv_powerlaw_quant(y, mu):\n",
    "#     return np.sign(y)*(x_max/mu)*(10**(np.abs(y)*np.log(1+mu)/x_max) - 1)\n",
    "    return np.sign(y)*((mu + 1)**np.abs(y) - 1)/mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize(x, S):\n",
    "    X = x.reshape((-1,1))\n",
    "    S = S.reshape((1,-1))\n",
    "    dists = abs(X-S)\n",
    "    \n",
    "    nearestIndex = dists.argmin(axis=1)\n",
    "    quantized = S.flat[nearestIndex]\n",
    "    \n",
    "    return quantized.reshape(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=10):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=10):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def signal_to_noise(original, decoded):\n",
    "    original = original.astype('float_')\n",
    "    decoded = decoded.astype('float_')\n",
    "    diff = len(original) - len(decoded)\n",
    "    \n",
    "    if diff < 0:\n",
    "        decoded = decoded[:diff]\n",
    "    if diff > 0:\n",
    "        decoded = np.append(decoded, np.zeros((diff,1)))\n",
    "        \n",
    "    signal = np.power(original, 2)\n",
    "    noise = np.power(original-decoded, 2)\n",
    "    \n",
    "    signal = np.where(signal == 0, np.finfo(np.float32).eps, signal)\n",
    "    noise = np.where(noise == 0, np.finfo(np.float32).eps, noise)\n",
    "    \n",
    "    return np.mean(np.log10(signal/noise)*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def absolute_threshold_hearing(f):\n",
    "    return 3.64*np.float_power(f/1000, -0.8) - \\\n",
    "        6.5*np.exp(-0.6*np.power(f/1000 - 3.3, 2)) + \\\n",
    "        np.float_power(10, -3)*np.power(f/1000, 4)\n",
    "\n",
    "def bark(f):\n",
    "    return 13*np.arctan(0.00076*f) + 3.5*np.arctan((f/7500)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cd_quality_audio(filename):\n",
    "    audio, sr = librosa.load(filename, sr=44100, dtype='float_')\n",
    "    max_int_value = 2**15 - 1\n",
    "    audio *= max_int_value\n",
    "    audio = audio.astype('int16')\n",
    "    return audio, sr\n",
    "    \n",
    "x, sr = load_cd_quality_audio(\"taxman.wav\")\n",
    "fs = 44100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ipd.Audio(x, rate=44100)\n",
    "# x = x[0:1000000]\n",
    "# x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_into_frames(signal, npoints):\n",
    "    # Find out how many frames are needed\n",
    "    nwholeframes = np.floor(len(signal)/npoints).astype('int')\n",
    "    nframes = np.ceil(len(signal)/npoints).astype('int')\n",
    "    # Pad the signal so that its length is divisible by nframes\n",
    "    padded = np.pad(signal, (0, npoints-len(signal)%nwholeframes), 'constant', constant_values=0.0)\n",
    "    # Reshape padded signal into nframes rows, each row is one frame\n",
    "    frames = padded.reshape((nframes, len(padded)//nframes))\n",
    "    return frames\n",
    "\n",
    "npoints = 1152\n",
    "nbands = 32\n",
    "nsubbands = 18\n",
    "\n",
    "# Divide original signal into frames, each frame consists of npoints\n",
    "x_frames = divide_into_frames(x, npoints)\n",
    "x_frames.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 1.0 / sr\n",
    "   \n",
    "k = np.arange(npoints // 2 + 1)\n",
    "f_k = k * sr / npoints\n",
    "b_k = bark(f_k)\n",
    "\n",
    "k_i = np.r_[1:49, 49:97:2, 97:255:4, 255:513:8]\n",
    "f_i = k_i * sr / npoints\n",
    "b_i = bark(f_i)\n",
    "ATH_i = absolute_threshold_hearing(f_i)\n",
    "subband_i = np.array([int(s) for s in np.round(f_i * nbands / (0.45 * sr) - 0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subband_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_allocation_table = np.array([10, 10, 10, 10, 9, 9, 9, 8, 8, 8, 8, \\\n",
    "                   8, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, \\\n",
    "                   4, 4, 4, 4, 4, 4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(object):\n",
    "    def __init__(self):\n",
    "        small  = np.array([-2, +2])\n",
    "        medium = np.array([-3, -2, +2, +3]) \n",
    "        large  = np.array([-6, -5, -4, -3, -2, +2, +3, +4, +5, +6])\n",
    "        xlarge  = np.linspace(-12, 12, 25, dtype='int')\n",
    "        self.neighbourhood = 512 * [None]\n",
    "        for _k in range(2, 63):\n",
    "            self.neighbourhood[_k] = small\n",
    "        for _k in range(63, 127):\n",
    "            self.neighbourhood[_k] = medium\n",
    "        for _k in range(127, 255):\n",
    "            self.neighbourhood[_k] = large\n",
    "        for _k in range(255, 501):\n",
    "            self.neighbourhood[_k] = xlarge\n",
    "    def __call__(self, k, P):\n",
    "        k_t = []\n",
    "        P_t = []\n",
    "        for _k in np.arange(3, 501):\n",
    "            if (P[_k-1] <= P[_k] and P[_k+1] <= P[_k]):\n",
    "                js = self.neighbourhood[_k]\n",
    "                if np.all(P[_k] - P[_k+js] >= 7):\n",
    "                    k_t.append(_k)\n",
    "                    P_t.append(P[_k-1] + P[_k] + P[_k+1])\n",
    "                    P[_k-1] = P[_k] = P[_k+1] = 0.0\n",
    "        return (np.array(k_t, dtype='uint16'), np.array(P_t)), (k, P)        \n",
    "\n",
    "classify = Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P_k_from_frame(frame, window, N, dB=True):\n",
    "    alpha = 1.0 / np.sqrt(sum(window(N)**2) / N)\n",
    "    frame = alpha * window(N) * frame\n",
    "\n",
    "    frame_fft_2 = abs(fft(frame)) ** 2\n",
    "\n",
    "    P_k = 2.0 * frame_fft_2[:(N // 2 + 1)] / N ** 2\n",
    "    P_k[0] = 0.5 * P_k[0]\n",
    "    if (N % 2 == 0):\n",
    "        P_k[-1] = 0.5 * P_k[-1]\n",
    "\n",
    "    P_k = 10.0 ** (96.0 / 10.0) * P_k\n",
    "    if dB:\n",
    "        P_k = 10.0 * np.log10(P_k)  \n",
    "    return P_k\n",
    "\n",
    "plt.plot(P_k_from_frame(x_frames[100], signal.windows.hann, 1152))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_by_critical_band(k, P):\n",
    "    b_k = bark(f_k)\n",
    "    cb_k = np.array([int(b) for b in np.floor(b_k)])\n",
    "    bands = [[[], []] for _ in np.arange(np.amax(cb_k) + 1)]\n",
    "    for _k, _P in zip(k, P):\n",
    "        band = bands[cb_k[_k]]\n",
    "        band[0].append(_k)\n",
    "        band[1].append(_P)\n",
    "    for b, band in enumerate(bands):\n",
    "        bands[b] = np.array(band)\n",
    "    return bands\n",
    "\n",
    "def merge_tonals(k_t, P_t):\n",
    "    bands = group_by_critical_band(k_t, P_t)\n",
    "    k_t_out, P_t_out = [], []\n",
    "    for band, k_P_s in enumerate(bands):\n",
    "        if len(k_P_s[0]):\n",
    "            k_max = None\n",
    "            P_max = - np.inf \n",
    "            for _k, _P in zip(*k_P_s):\n",
    "               if _P > P_max:\n",
    "                   k_max = _k\n",
    "                   P_max = _P\n",
    "            k_t_out.append(k_max)\n",
    "            P_t_out.append(P_max)\n",
    "    return np.array(k_t_out, dtype='uint16'), np.array(P_t_out)\n",
    "\n",
    "def merge_non_tonals(k_nt, P_nt):\n",
    "    bands = group_by_critical_band(k_nt, P_nt)\n",
    "    k_nt_out = np.zeros(len(bands), dtype='uint8')\n",
    "    P_nt_out = np.zeros(len(bands))\n",
    "    for band, k_P_s in enumerate(bands):\n",
    "        if len(k_P_s[0]):\n",
    "            k, P = k_P_s\n",
    "            P_sum = sum(P)\n",
    "            if P_sum == 0.0:\n",
    "                P = np.ones_like(P)\n",
    "            k_mean = int(round(np.average(k, weights=P))) \n",
    "            k_nt_out[band] = k_mean\n",
    "            P_nt_out[band] = P_sum\n",
    "    return k_nt_out, P_nt_out\n",
    "\n",
    "def threshold(k, P):\n",
    "    ATH_k = 10 ** (absolute_threshold_hearing(f_k) / 10.0)\n",
    "    k_out, P_out = [], []\n",
    "    for (_k, _P) in zip(k, P):\n",
    "        if _P > ATH_k[_k]:\n",
    "            k_out.append(_k)\n",
    "            P_out.append(_P)\n",
    "    return np.array(k_out), np.array(P_out)\n",
    "\n",
    "def excitation_pattern(b, b_m, I_m, tonal):\n",
    "    db = b - b_m\n",
    "    db_1 = np.minimum(db + 1.0, 0.0)\n",
    "    db_2 = np.minimum(db      , 0.0)\n",
    "    db_3 = np.maximum(db      , 0.0)\n",
    "    db_4 = np.maximum(db - 1.0, 0.0)    \n",
    "    mask  = I_m \\\n",
    "          + (11.0 - 0.40 * I_m) * db_1 \\\n",
    "          + ( 6.0 + 0.40 * I_m) * db_2 \\\n",
    "          - (17.0             ) * db_3 \\\n",
    "          + (       0.15 * I_m) * db_4\n",
    "    if tonal:\n",
    "        mask += -1.525 - 0.275 * b - 4.5\n",
    "    else:\n",
    "        mask += -1.525 - 0.175 * b - 0.5\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskers(frame, merge=True, ATH_threshold=True):\n",
    "    P_k = P_k_from_frame(frame, signal.windows.hann, 1152)\n",
    "    (k_t, P_t), (k_nt, P_nt) = classify(k, P_k)\n",
    "#     if merge:\n",
    "# #         k_t, P_t = merge_tonals(k_t, P_t)\n",
    "#         k_nt, P_nt = merge_non_tonals(k_nt, P_nt)\n",
    "#     if ATH_threshold:\n",
    "#         k_t, P_t = threshold(k_t, P_t)\n",
    "#         k_nt, P_nt = threshold(k_nt, P_nt)\n",
    "    return (k_t, P_t), (k_nt, P_nt)\n",
    "\n",
    "(k_t, P_t), (k_nt, P_nt) = maskers(x_frames[500])\n",
    "# len(group_by_critical_band(k_t, P_t))\n",
    "k_nt[P_nt==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def SMR_from_frame(frame):\n",
    "    frame = np.array(frame, copy=False)\n",
    "\n",
    "    mask_i = 10.0 ** (ATH_i / 10.0)\n",
    "\n",
    "    (k_t, P_t), (k_nt, P_nt) = maskers(frame)\n",
    "\n",
    "    for masker_index in np.arange(len(k_t)):\n",
    "        _b, _P = b_k[ k_t[masker_index] ], P_t[ masker_index ]\n",
    "        ep = excitation_pattern(b_i, b_m=_b, I_m=10.0*np.log10(_P), tonal=True)\n",
    "        mask_i += 10.0 ** (ep / 10.0)\n",
    "\n",
    "    for masker_index in np.arange(len(k_nt)):\n",
    "        _b, _P = b_k[k_nt[masker_index]], P_nt[masker_index]\n",
    "        ep = excitation_pattern(b_i, b_m=_b, I_m=10.0*np.log10(_P), tonal=False) \n",
    "        mask_i += 10.0 ** (ep / 10.0)\n",
    "\n",
    "    mask_i = 10.0 * np.log10(mask_i)\n",
    "\n",
    "    subband_masks = [[] for _ in range(32)] \n",
    "    subband_MMT = np.zeros(32) # MMT = Minimum Masking Threshold\n",
    "    subband_LSB = np.zeros(32) # LSB = Sound Pressure Level\n",
    "    subband_SMR = np.zeros(32) # SMR = Signal To Mask Ratio\n",
    "\n",
    "    for i, _mask_i in enumerate(mask_i):\n",
    "        subband_masks[subband_i[i]].append(_mask_i)\n",
    "\n",
    "    for i, _masks in enumerate(subband_masks):\n",
    "        subband_MMT[i] = np.amin(_masks)\n",
    "\n",
    "    P_k = P_k_from_frame(frame, signal.windows.hann, 1152)\n",
    "    for i, _masks in enumerate(subband_MMT):\n",
    "        max_scalefactor = 20*np.log10((2**bit_allocation_table[i]-1)*32768)-10\n",
    "        subband_LSB[i] = np.maximum(np.max(P_k), max_scalefactor)\n",
    "\n",
    "    subband_SMR = subband_LSB - subband_MMT\n",
    "    \n",
    "    return np.clip(subband_SMR, 0, None)\n",
    "\n",
    "# SMR_from_frame(x_frames[100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psychoacoustic_analysis(x_frames, nbands):\n",
    "    SMR = np.zeros((x_frames.shape[0], nbands))\n",
    "    for i in range(0, x_frames.shape[0]):\n",
    "        if np.any(x_frames[i]):\n",
    "            SMR[i,:] = SMR_from_frame(x_frames[i])\n",
    "        else:\n",
    "            SMR[i,:] = np.zeros(nbands)\n",
    "    \n",
    "    return SMR\n",
    "\n",
    "t1 = time.time()\n",
    "x_SMR = psychoacoustic_analysis(x_frames, nbands)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_length = 96\n",
    "window_function = np.sin(np.pi / 2 * \\\n",
    "                       np.power(np.sin(np.pi / window_length * \\\n",
    "                       np.arange(0.5, window_length + 0.5)), 2))\n",
    "num_blocks = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from PQMFB import *\n",
    "def filter_banks(frames, nbands, num_blocks):\n",
    "#     fb=np.sin(np.pi/(2*32)*(np.arange(int(1.5*32))+0.5))\n",
    "#     fb = np.concatenate((fb,np.flipud(fb)))\n",
    "    x_bands = np.zeros((nbands, frames.shape[0], num_blocks))\n",
    "    for i in range(0, frames.shape[0]):\n",
    "        x_bands[:,i,:] = PQMFBana(frames[i], nbands, window_function)\n",
    "    \n",
    "    return x_bands\n",
    "\n",
    "t1 = time.time()\n",
    "x_bands = filter_banks(x_frames, nbands, num_blocks)\n",
    "print(time.time() - t1)\n",
    "x_bands.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantizedFrame(object):\n",
    "    def __init__(self, scaling_factors=np.array([]), data=np.array([], dtype='int8')):\n",
    "        self.scaling_factors = scaling_factors\n",
    "        self.data = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantization(x_bands, x_SMR, nbands, nsubbands):\n",
    "    x_SMR = x_SMR.astype('int')\n",
    "    max_bits = np.amax(bit_allocation_table)\n",
    "    SMR_arr = np.arange(np.amin(x_SMR), np.amax(x_SMR)+1)\n",
    "    SMR_to_bits = np.round(SMR_arr/(np.amax(x_SMR) / max_bits)).astype('uint8')\n",
    "    SMR_to_mu = SMR_arr*(-255/np.amax(x_SMR)) + 255\n",
    "\n",
    "    quantized_signal = []\n",
    "    frame_separator = 2**(max_bits+1)\n",
    "    for i in range(0, x_bands.shape[1]):\n",
    "        quantfr = QuantizedFrame()\n",
    "        for j in range(0, nbands):\n",
    "            band_smr = x_SMR[i,j]\n",
    "            bit_alloc = SMR_to_bits[band_smr]\n",
    "    #         print(bit_alloc)\n",
    "            if bit_alloc > 6:\n",
    "                quantized_mdct = powerlaw_quant(x_bands[j,i,:], 255)/band_smr\n",
    "    #             print(signal_to_noise(x_subbands[j,i,:], inv_powerlaw_quant(quantized_mdct*band_smr,255)))\n",
    "                quantized_mdct = quantized_mdct.astype('float16')\n",
    "                quantfr.data = np.append(quantfr.data, quantized_mdct)\n",
    "                quantfr.scaling_factors = np.append(quantfr.scaling_factors, band_smr)\n",
    "\n",
    "        quantized_signal.append(quantfr)\n",
    "    \n",
    "    return quantized_signal\n",
    "\n",
    "t1 = time.time()\n",
    "quantized_signal = quantization(x_bands, x_SMR, nbands, nsubbands)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncodedSignal(object):\n",
    "    def __init__(self):\n",
    "        self.huffman_table_signal = None\n",
    "        self.signal = []\n",
    "        self.huffman_table_scaling = None\n",
    "        self.scaling_factors = []\n",
    "        self.nframes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huffman_encoding(quantized_signal):\n",
    "    encoded_signal = EncodedSignal()\n",
    "    encoded_signal.nframes = len(quantized_signal)\n",
    "    for i, frame in enumerate(quantized_signal):\n",
    "        encoded_signal.signal.extend(frame.data.tolist())\n",
    "        encoded_signal.signal.append(999999)\n",
    "        \n",
    "        encoded_signal.scaling_factors.extend(frame.scaling_factors)\n",
    "        \n",
    "    signal_codec = HuffmanCodec.from_data(encoded_signal.signal)\n",
    "    encoded_signal.huffman_table_signal = signal_codec.get_code_table()\n",
    "    \n",
    "    scale_codec = HuffmanCodec.from_data(encoded_signal.scaling_factors)\n",
    "    encoded_signal.huffman_table_scaling = scale_codec.get_code_table()\n",
    "    \n",
    "    encoded_signal.signal = signal_codec.encode(encoded_signal.signal)\n",
    "    encoded_signal.scaling_factors = scale_codec.encode(encoded_signal.scaling_factors)\n",
    "    return encoded_signal\n",
    "\n",
    "encoded_signal = huffman_encoding(quantized_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(encoded_signal.signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = codec.decode(encoded)\n",
    "len(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compressionRatio(original, decoded):\n",
    "    o_str = pickle.dumps(original)\n",
    "    e_str = pickle.dumps(decoded)\n",
    "    return sys.getsizeof(o_str)/sys.getsizeof(e_str)\n",
    "\n",
    "compressionRatio(x,encoded_signal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# def decode(encoded_signal):\n",
    "signal_decoder = HuffmanCodec(code_table=encoded_signal.huffman_table_signal, check=False)\n",
    "scaling_decoder = HuffmanCodec(code_table=encoded_signal.huffman_table_scaling, check=False)\n",
    "decoded_signal = np.array(signal_decoder.decode(encoded_signal.signal))\n",
    "decoded_scaling = np.array(signal_decoder.decode(encoded_signal.scaling_factors))\n",
    "\n",
    "empty_frame = np.array([0]*npoints)\n",
    "mdct_per_frame = num_blocks\n",
    "decoded_final = np.zeros((encoded_signal.nframes, npoints))\n",
    "frame_separator = 999999\n",
    "\n",
    "frame_no = 0\n",
    "scale_no = 0\n",
    "for i in range(0, len(decoded_signal)-1):\n",
    "    if decoded_signal[i] == frame_separator and decoded_signal[i+1] == frame_separator:\n",
    "        decoded_final[frame_no,:] = empty_frame\n",
    "        frame_no += 1\n",
    "        continue\n",
    "    if decoded_signal[i] == frame_separator:\n",
    "        decoded_mdct = np.zeros((nbands, num_blocks))\n",
    "#         frame_data = np.array(huffman_decoder.decode(frame.data))\n",
    "    #     print(frame_data)\n",
    "        idx = i\n",
    "        for j in range(0, 32):\n",
    "            if decoded_signal[end+1] != frame_separator:\n",
    "                idx = i + j\n",
    "                scale_factor = decoded_scaling[scale_no]\n",
    "                scale_no += 1\n",
    "                start = i+1+j*mdct_per_frame\n",
    "                end = i+1+(j+1)*mdct_per_frame\n",
    "                encoded_mdct = decoded_signal[start:end]*scale_factor\n",
    "                decoded_mdct[j] = inv_powerlaw_quant(encoded_mdct, 255)\n",
    "        i = idx\n",
    "        decoded_frame = PQMFBsyn(decoded_mdct, window_function)\n",
    "\n",
    "        diff = 1152 - len(decoded_frame)\n",
    "        if diff < 0:\n",
    "            decoded_final[frame_no,:] = decoded_frame[:diff]\n",
    "        if diff > 0:\n",
    "            decoded_final[frame_no,:] = np.append(decoded_frame, np.zeros((diff,1)))\n",
    "        frame_no += 1\n",
    "\n",
    "# return decoded_signal\n",
    "\n",
    "t1 = time.time()\n",
    "# decoded_signal = decode(encoded_signal)\n",
    "print(time.time() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     alpha_value = 5\n",
    "#     Kaiser-Bessel-derived (KBD) window as used in the AC-3 audio coding format\n",
    "#     window_function = np.kaiser(int(window_length/2)+1, alpha_value*np.pi)\n",
    "#     window_function2 = np.cumsum(window_function[0:int(window_length/2)])\n",
    "#     window_function = np.sqrt(np.concatenate((window_function2, window_function2[int(window_length/2)::-1]))\n",
    "#                               / np.sum(window_function))\n",
    "# window_length = 128\n",
    "# # window_function = np.sin(np.pi / 2 * np.power(np.sin(np.pi / window_length * np.arange(0.5, window_length + 0.5)), 1))\n",
    "# window_function = np.sin(np.pi/(2*576)*(np.arange(int(1.5*576))+0.5))\n",
    "\n",
    "# plt.plot(window_function)\n",
    "\n",
    "# tmp_mdct = ctt.mdct(x_bands[0,500,:], window_function)\n",
    "# tmp_imdct = ctt.imdct(tmp_mdct, window_function)\n",
    "# tmp_mdct.shape\n",
    "total*38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_to_noise(x, decoded_signal.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ipd.Audio(decoded_signal.flatten(), rate=44100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoded_signal[100:]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}